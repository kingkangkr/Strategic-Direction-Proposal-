{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f27ba79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "META crashing hard !!!!!\n",
      "I am about to lose job. What is the ideal timeframe for getting a mid level software developer job\n",
      "Scotiabank referral?\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import time\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://www.teamblind.com/topics/Industries/Financial-Services\"\n",
    "driver.get(url)\n",
    "###############################################################\n",
    "#Output after auto scrolling down for 30 seconds \n",
    "    \n",
    "def doScrollDown(whileSeconds):\n",
    "    start = datetime.datetime.now()\n",
    "    end = start + datetime.timedelta(seconds=whileSeconds)\n",
    "    while True:\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(1)\n",
    "        if datetime.datetime.now() > end:\n",
    "            break\n",
    "doScrollDown(10)\n",
    "html1 = driver.page_source \n",
    "soup = BeautifulSoup (html1, 'html.parser' ) \n",
    "title_list = soup.select ( \"div.h_tit > strong\" ) \n",
    "titles = [strong.get_text(strip=True) for strong in title_list]\n",
    "#1st topic\n",
    "print(titles[0])\n",
    "#100th topic\n",
    "print(titles[99])\n",
    "#200th topic\n",
    "print(titles[199])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be7ca63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                title  \\\n",
      "0  학생들 나눠준 공짜 태블릿, 3년간 수리비만 11억5000만원   \n",
      "1  \"싸움 말리다 책상 넘어뜨린 교사에 줄소송, 교권 침해 해당\"   \n",
      "2   고려대, 기증받은 17세기 고미술품 분실…경찰 미제사건 등록   \n",
      "3                   생애설계 이론과 실무를 한번에!   \n",
      "\n",
      "                                url to detailed news  \n",
      "0  https://n.news.naver.com/mnews/article/023/000...  \n",
      "1  https://n.news.naver.com/mnews/article/003/001...  \n",
      "2  https://n.news.naver.com/mnews/article/001/001...  \n",
      "3  https://n.news.naver.com/mnews/article/009/000...  \n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_soup_obj(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36 Edg/118.0.2088.61'\n",
    "    }\n",
    "    res = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(res.text, 'lxml')\n",
    "    return soup\n",
    "\n",
    "area_url = \"https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid1=102&sid2=250\"\n",
    "soup = get_soup_obj(area_url)\n",
    "titles = soup.find('ul', class_='type06_headline').find_all(\"li\", limit=4)\n",
    "title_list = []\n",
    "url_list = []\n",
    "\n",
    "for title in titles:\n",
    "    try:\n",
    "        text1 = title.img.attrs.get('alt')\n",
    "    except:\n",
    "        text1 = title.a.text\n",
    "    title_list.append(text1)\n",
    "    text2 = title.a.attrs.get('href')\n",
    "    url_list.append(text2)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'title': title_list, 'url to detailed news': url_list})\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b901913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
